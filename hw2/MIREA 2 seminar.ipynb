{"cells":[{"cell_type":"markdown","metadata":{"id":"RQ8rTFmQ0ueR"},"source":["# **Разбор практики 1.**"]},{"cell_type":"markdown","metadata":{"id":"9P9bWaC9QQJm"},"source":["## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hh8sSJkEWNmT"},"outputs":[],"source":["class Neuron(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.fc = torch.nn.Linear(1, 1, bias=True)\n","\n","  def forward(self, x):\n","    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1662381955665,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"r9HoH1koVQXi","outputId":"e3020bb5-04c1-45cf-937a-77d6c2337325"},"outputs":[{"data":{"text/plain":["(Parameter containing:\n"," tensor([[-0.9774]], requires_grad=True), Parameter containing:\n"," tensor([0.1165], requires_grad=True))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["neuron = Neuron()\n","neuron.fc.weight, neuron.fc.bias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1662381956994,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"MLmGhtWFTYlV","outputId":"9ca8cb0a-4683-44d6-e910-69e6908a587c"},"outputs":[{"data":{"text/plain":["(Parameter containing:\n"," tensor([[-1.]], requires_grad=True), Parameter containing:\n"," tensor([1.], requires_grad=True))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["neuron.fc.weight.data = torch.tensor([[-1.0]])\n","neuron.fc.bias.data = torch.tensor([1.0])\n","neuron.fc.weight, neuron.fc.bias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1662381965316,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"UFr5InkDTf-r","outputId":"6504e778-9bd4-4c5f-c2f8-67d22bb522d5"},"outputs":[{"data":{"text/plain":["tensor([1.], grad_fn=<NotImplemented>)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([0.0])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1662381972049,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"sXJqgPEwAwHa","outputId":"12c3a893-da2c-4b19-de63-0a803b132b38"},"outputs":[{"data":{"text/plain":["tensor([0.], grad_fn=<NotImplemented>)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1.0])\n","neuron(x)"]},{"cell_type":"markdown","metadata":{"id":"TRxJxcRJQsMz"},"source":["## **Задача 3**. Cделать нейрон, соответствующий оператору И."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dvDtA7HX3V6"},"outputs":[],"source":["class Neuron(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.fc = torch.nn.Linear(2, 1)\n","\n","  def forward(self, x):\n","    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1662382014810,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"olMqAnQtX5NQ","outputId":"d3b3ffe4-f637-4338-a46f-9db503a316ab"},"outputs":[{"data":{"text/plain":["(Parameter containing:\n"," tensor([[-0.4475]], requires_grad=True), Parameter containing:\n"," tensor([-0.0402], requires_grad=True))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["neuron = Neuron()\n","neuron.fc.weight, neuron.fc.bias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1662382021741,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"kAtwMX7HQ0aj","outputId":"53bb0196-ecaf-489c-858e-c3d420d454aa"},"outputs":[{"data":{"text/plain":["(Parameter containing:\n"," tensor([[1., 1.]], requires_grad=True), Parameter containing:\n"," tensor([-1.5000], requires_grad=True))"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n","neuron.fc.bias.data = torch.tensor([-1.5])\n","neuron.fc.weight, neuron.fc.bias"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1662382028852,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"P27EdNkrXloh","outputId":"96718328-9f63-41df-8077-3791a2d6b905"},"outputs":[{"data":{"text/plain":["tensor([0.], grad_fn=<NotImplemented>)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([0.0, 0.0])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1662382032639,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"-BJc_ipGrei3","outputId":"c04b6405-d7ae-4e49-a6c1-6f478572f17a"},"outputs":[{"data":{"text/plain":["tensor([0.], grad_fn=<NotImplemented>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1.0, 0.0 ])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1662382034613,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"KjVTdBf-rei5","outputId":"2788282c-a684-43c1-f219-3d16f45f14d3"},"outputs":[{"data":{"text/plain":["tensor([0.], grad_fn=<NotImplemented>)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([0.0, 1.0 ])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1662382036293,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"kyomxCJUrei5","outputId":"9b335917-e009-479c-e75d-9d1565422b8e"},"outputs":[{"data":{"text/plain":["tensor([1.], grad_fn=<NotImplemented>)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1.0, 1.0 ])\n","neuron(x)"]},{"cell_type":"markdown","metadata":{"id":"MRuSrP7JQ00i"},"source":["## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23RuhFqbQ24-"},"outputs":[],"source":["neuron.fc.weight.data = torch.tensor([[1., 1.]])\n","neuron.fc.bias.data = torch.tensor([-0.5])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1662383705500,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"i-BZHFqnXpLL","outputId":"7105825d-66f2-48db-a250-8a3bfe6be45d"},"outputs":[{"data":{"text/plain":["tensor([0.], grad_fn=<NotImplemented>)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([0.0, 0.0])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1662383708062,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"TZuFtRlvyixQ","outputId":"8181961c-7669-4a37-c4ce-1277622af170"},"outputs":[{"data":{"text/plain":["tensor([1.], grad_fn=<NotImplemented>)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1.0, 0.0 ])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1662383709543,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"jyu88Kg0yixR","outputId":"26449834-8084-4c6a-a696-141449d0622f"},"outputs":[{"data":{"text/plain":["tensor([1.], grad_fn=<NotImplemented>)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([0.0, 1.0 ])\n","neuron(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1662383711640,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"r2OhYEC7yixS","outputId":"0100e5f4-c3a6-4188-9c5b-42cf823eb1e3"},"outputs":[{"data":{"text/plain":["tensor([1.], grad_fn=<NotImplemented>)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([1.0, 1.0 ])\n","neuron(x)"]},{"cell_type":"markdown","metadata":{"id":"1b95Z8u7Q3OL"},"source":["## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWP7ee7tjCGv"},"outputs":[],"source":["neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n","neuron.fc.bias.data = torch.tensor([0.0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgDrZ7PBjGwJ"},"outputs":[],"source":["x = torch.tensor([0.0, 0.0])\n","neuron(x)"]},{"cell_type":"markdown","metadata":{"id":"zjM7DFps2rBi"},"source":["# **Занятие 2.**"]},{"cell_type":"markdown","metadata":{"id":"KlS1ciOPBg7g"},"source":["# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"]},{"cell_type":"markdown","metadata":{"id":"kP06X1SrzLlm"},"source":["[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n","\n","[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n","\n","[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n","\n","[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"alR-VHX_gnQK"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ipOjjh8OCk4u"},"outputs":[],"source":["def show_tensor_params(*tensors):\n","  for x in tensors:\n","    print('---')\n","    print(f\"data - {x.data}\")\n","    print(f\"grad - {x.grad}\")\n","    print(f\"grad_fn - {x.grad_fn}\")\n","    print(f\"req_grad - {x.requires_grad}\")\n","    print(f\"is_leaf - {x.is_leaf}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670247357748,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"lXas0qEnybl9","outputId":"4385d7e1-bc39-4647-8f40-559c403f8ed7"},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","data - 5.0\n","grad - None\n","grad_fn - None\n","req_grad - False\n","is_leaf - True\n"]}],"source":["x = torch.tensor(5.0)\n","show_tensor_params(x)"]},{"cell_type":"markdown","metadata":{"id":"NuymHxbjzDfP"},"source":["All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n","\n","For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n","\n","Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"O5NE4zRPyqTT"},"outputs":[],"source":["#Slide A4\n","a = torch.tensor(2.0, requires_grad=True)\n","b = torch.tensor(3.0)\n","c = a*b\n","\n","c.backward()\n","# (2 * c).backward()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670247440672,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"q-TbdvmH-oaM","outputId":"67a03e27-8396-419a-fe3f-4b530dabfec8"},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","data - 2.0\n","grad - 3.0\n","grad_fn - None\n","req_grad - True\n","is_leaf - True\n","---\n","data - 3.0\n","grad - None\n","grad_fn - None\n","req_grad - False\n","is_leaf - True\n","---\n","data - 6.0\n","grad - None\n","grad_fn - <MulBackward0 object at 0x000001D7A3147F10>\n","req_grad - True\n","is_leaf - False\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yaroslav\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:482.)\n","  return self._grad\n"]}],"source":["show_tensor_params(a, b, c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqUcFO2rCXni"},"outputs":[],"source":["#Slide Simple5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYTsuKc3Fn8r"},"outputs":[],"source":["a = torch.tensor(2.0, requires_grad=True)\n","b = torch.tensor(3.0, requires_grad=True)\n","c = a*b\n","d = torch.tensor(4.0, requires_grad=True)\n","e = c*d\n","\n","c.retain_grad()\n","e.retain_grad()\n","e.backward()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670247560082,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"egTBJvIBF5EO","outputId":"3d1429c0-b930-49e6-c24d-268dfb6d7460"},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","data - 2.0\n","grad - 12.0\n","grad_fn - None\n","req_grad - True\n","is_leaf - True\n","---\n","data - 3.0\n","grad - 8.0\n","grad_fn - None\n","req_grad - True\n","is_leaf - True\n","---\n","data - 6.0\n","grad - 4.0\n","grad_fn - <MulBackward0 object at 0x7f2d51766790>\n","req_grad - True\n","is_leaf - False\n","---\n","data - 4.0\n","grad - 6.0\n","grad_fn - None\n","req_grad - True\n","is_leaf - True\n","---\n","data - 24.0\n","grad - 1.0\n","grad_fn - <MulBackward0 object at 0x7f2d51770110>\n","req_grad - True\n","is_leaf - False\n"]}],"source":["show_tensor_params(a, b, c, d, e)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":245,"status":"error","timestamp":1670247656675,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"W5Cs2_REGgOS","outputId":"1f6d02d7-001f-4974-8528-3175f60a6081"},"outputs":[{"ename":"RuntimeError","evalue":"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn [6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m e \u001b[39m=\u001b[39m c\u001b[39m*\u001b[39md\n\u001b[0;32m      7\u001b[0m c \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> 9\u001b[0m e\u001b[39m.\u001b[39;49mbackward()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."]}],"source":["#In place 1\n","a = torch.tensor(2.0, requires_grad=True)\n","b = torch.tensor(3.0, requires_grad=True)\n","c = a*b\n","d = torch.tensor(4.0, requires_grad=True)\n","e = c*d\n","c += 1\n","\n","e.backward()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1670247662833,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"-WeqfWzYGhKG","outputId":"62245ba0-49c5-4703-999f-b6a81a5a5839"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","0\n"]}],"source":["print(c._version)\n","print(d._version)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"iLZ3Z4qIH4J4"},"outputs":[],"source":["#In place 2\n","a = torch.tensor(2.0, requires_grad=True)\n","b = torch.tensor(3.0, requires_grad=True)\n","c = a*b\n","d = torch.tensor(4.0, requires_grad=True)\n","e = c+d\n","c += 1\n","\n","e.backward()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670247696760,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"3ySSjlRUIH0e","outputId":"36d5594c-d9f2-4b41-ea60-84dc03e55053"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","0\n"]}],"source":["print(c._version)\n","print(d._version)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4jbSqPGkILEw"},"outputs":[],"source":["# отвязка от графа\n","k = e.detach()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1670247793558,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"pLKUQ08AJhZT","outputId":"9c7c338a-a5b7-44ca-d396-44e7fca170a8"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["k.storage == e.storage"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670247795111,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"Eqo-PW2kJkaG","outputId":"d82e5cb3-e0e3-4a13-ae39-b16c55111648"},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","data - 10.0\n","grad - None\n","grad_fn - <AddBackward0 object at 0x000001D7BE8A8310>\n","req_grad - True\n","is_leaf - False\n","---\n","data - 10.0\n","grad - None\n","grad_fn - None\n","req_grad - False\n","is_leaf - True\n"]}],"source":["show_tensor_params(e, k)"]},{"cell_type":"markdown","metadata":{"id":"B8urvcsAKi62"},"source":["# Создание собственной библиотеки автоматического дифференцирования"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"txwYkEHMftme"},"outputs":[],"source":["import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"urGQXw9GgdQt"},"source":["### Простой пример"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"bPNsEPbZfwXm"},"outputs":[],"source":["def f(x):\n","  return 3*x**2 - 4*x + 5"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1670247842923,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"IKMjYubGfzo5","outputId":"251797af-dea0-4cac-9617-4ea625e46f18"},"outputs":[{"data":{"text/plain":["20.0"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["f(3.0)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1670247862131,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"2Mufja5Mf2dD","outputId":"ef31f0a0-2f59-44a2-deab-6c6653138789"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x1d7c20bd5d0>]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["xs = np.arange(-5, 5, 0.25)\n","ys = f(xs)\n","plt.plot(xs, ys)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1670247921591,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"kzRAdjhFgGo8","outputId":"3867db0e-6068-470a-bab3-caf547a621f6"},"outputs":[{"data":{"text/plain":["8.000003001384925"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["h = 0.000001\n","x = 2\n","(f(x + h) - f(x))/h"]},{"cell_type":"markdown","metadata":{"id":"dOszwXaTgkd4"},"source":["### Более сложный пример"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1670247990537,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"BOzPl8NWghve","outputId":"8a1b642f-8361-4f35-a8fc-15a806050d59"},"outputs":[{"name":"stdout","output_type":"stream","text":["4.0\n"]}],"source":["a = 2.0\n","b = -3.0\n","c = 10.0\n","d = a*b + c\n","print(d)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670248061128,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"P9Xx4_omgrkm","outputId":"12af0302-51e9-433e-ebca-cca81b6d860f"},"outputs":[{"name":"stdout","output_type":"stream","text":["d1 4.0\n","d2 4.0001\n","slope 0.9999999999976694\n"]}],"source":["h = 0.0001\n","\n","# inputs\n","a = 2.0\n","b = -3.0\n","c = 10.0\n","\n","d1 = a*b + c\n","c += h\n","d2 = a*b + c\n","\n","print('d1', d1)\n","print('d2', d2)\n","print('slope', (d2 - d1)/h)"]},{"cell_type":"markdown","metadata":{"id":"wle8vv7_grKJ"},"source":[]},{"cell_type":"markdown","metadata":{"id":"dlDJrMMsOgNh"},"source":["https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"sPyPkdq5RH94"},"outputs":[],"source":["from torch.autograd import Function"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"F5-hnsEiPIz9"},"outputs":[],"source":["class Exp(Function):\n","  \"\"\"\n","    We can implement our own custom autograd Functions by subclassing\n","    torch.autograd.Function and implementing the forward and backward passes\n","    which operate on Tensors.\n","    \"\"\"\n","\n","  @staticmethod\n","  def forward(ctx, i):\n","    \"\"\"\n","        In the forward pass we receive a Tensor containing the input and return\n","        a Tensor containing the output. ctx is a context object that can be used\n","        to stash information for backward computation. You can cache arbitrary\n","        objects for use in the backward pass using the ctx.save_for_backward method.\n","    \"\"\"\n","    result = i.exp()\n","    ctx.save_for_backward(result)\n","    return result\n","\n","  @staticmethod\n","  def backward(ctx, grad_output):\n","    \"\"\"\n","        In the backward pass we receive a Tensor containing the gradient of the loss\n","        with respect to the output, and we need to compute the gradient of the loss\n","        with respect to the input.\n","    \"\"\"\n","    print(ctx.saved_tensors)\n","    result, = ctx.saved_tensors\n","    return grad_output * result"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670248589566,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"elaOA8bdRiMc","outputId":"5227a995-2020-4242-d479-bacf8eddff33"},"outputs":[{"data":{"text/plain":["tensor(7.3891, grad_fn=<ExpBackward>)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Use it by calling the apply method\n","input = torch.tensor(2.0, requires_grad=True)\n","output = Exp.apply(input)\n","output"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219,"status":"ok","timestamp":1670248594054,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"JlcZLt-RSGgG","outputId":"676d6f78-d254-4cfb-c3c5-1a8e5a1c8826"},"outputs":[{"data":{"text/plain":["7.38905609893065"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import math\n","math.exp(2.0)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1670248601869,"user":{"displayName":"Александр Корчемный","userId":"14584717838032981888"},"user_tz":-180},"id":"Om6dn414SQeA","outputId":"fe644e9d-debd-489e-de24-e287bda96f6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor(7.3891, grad_fn=<ExpBackward>),)\n","---\n","data - 7.389056205749512\n","grad - None\n","grad_fn - <torch.autograd.function.ExpBackward object at 0x000001D7C2129380>\n","req_grad - True\n","is_leaf - False\n","---\n","data - 2.0\n","grad - 7.389056205749512\n","grad_fn - None\n","req_grad - True\n","is_leaf - True\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yaroslav\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:482.)\n","  return self._grad\n"]}],"source":["output.backward()\n","show_tensor_params(output)\n","show_tensor_params(input)"]},{"cell_type":"markdown","metadata":{"id":"d_14IqfeSnLM"},"source":["**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":3231,"status":"ok","timestamp":1670258018540,"user":{"displayName":"Ярослав Паламарчук","userId":"08021972334549004098"},"user_tz":-180},"id":"i5cNegVYOd8u"},"outputs":[],"source":["import torch\n","\n","\n","class Polynomial(torch.autograd.Function):\n","    \"\"\"\n","    We can implement our own custom autograd Functions by subclassing\n","    torch.autograd.Function and implementing the forward and backward passes\n","    which operate on Tensors.\n","    \"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, input):\n","        \"\"\"\n","        In the forward pass we receive a Tensor containing the input and return\n","        a Tensor containing the output. ctx is a context object that can be used\n","        to stash information for backward computation. You can cache arbitrary\n","        objects for use in the backward pass using the ctx.save_for_backward method.\n","        \"\"\"\n","        ctx.save_for_backward(input)\n","        return 0.5 * (5 * input ** 3 - 3 * input)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        \"\"\"\n","        In the backward pass we receive a Tensor containing the gradient of the loss\n","        with respect to the output, and we need to compute the gradient of the loss\n","        with respect to the input.\n","        \"\"\"\n","        input, = ctx.saved_tensors\n","        return (7.5 * input ** 2 - 1.5) * grad_output"]},{"cell_type":"markdown","metadata":{"id":"fA2PNhudUNij"},"source":["Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать класс Value "]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1670258022434,"user":{"displayName":"Ярослав Паламарчук","userId":"08021972334549004098"},"user_tz":-180},"id":"chDdD9oSUlUJ"},"outputs":[],"source":["import torch\n","\n","\n","class Value:\n","    \"\"\" stores a single scalar value and its gradient \"\"\"\n","\n","    def __init__(self, data, _children=(), _op=''):\n","        self.data = data\n","        self.grad = 0\n","        # internal variables used for autograd graph construction\n","        self._backward = lambda: None # function \n","        self._prev = set(_children) # set of Value objects\n","        self._op = _op # the op that produced this node, string ('+', '-', ....)\n","\n","    def __add__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data + other.data, _children=(self, other), _op='+')\n","\n","\n","        def _backward():\n","            self.grad += out.grad\n","            other.grad += out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __mul__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data * other.data, _children=(self, other), _op='*')\n","\n","        def _backward():\n","            self.grad += other.data * out.grad\n","            other.grad += self.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __pow__(self, other):\n","        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n","        out = Value(self.data ** other, _children=(self,), _op=f'**{other}')\n","\n","        def _backward():\n","            self.grad += (other * self.data ** (other - 1)) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def relu(self):\n","        out = Value(max(0, self.data), _children=(self,), _op='ReLU')\n","        def _backward():\n","            self.grad += (out.data > 0) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def backward(self):\n","\n","        # topological order all of the children in the graph\n","        topo = []\n","        visited = set()\n","        def build_topo(v):\n","            if v not in visited:\n","                visited.add(v)\n","                for child in v._prev:\n","                    build_topo(child)\n","                topo.append(v)\n","        build_topo(self)\n","\n","        # go one variable at a time and apply the chain rule to get its gradient\n","        self.grad = 1\n","        for v in reversed(topo):\n","            v._backward()\n","\n","    def __neg__(self): # -self\n","        return self * -1\n","\n","    def __radd__(self, other): # other + self\n","        return self + other\n","\n","    def __sub__(self, other): # self - other\n","        return self + (-other)\n","\n","    def __rsub__(self, other): # other - self\n","        return other + (-self)\n","\n","    def __rmul__(self, other): # other * self\n","        return self * other\n","\n","    def __truediv__(self, other): # self / other\n","        return self * other**-1\n","\n","    def __rtruediv__(self, other): # other / self\n","        return other * self**-1\n","\n","    def __repr__(self):\n","        return f\"Value(data={self.data}, grad={self.grad})\""]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":985,"status":"ok","timestamp":1670258027051,"user":{"displayName":"Ярослав Паламарчук","userId":"08021972334549004098"},"user_tz":-180},"id":"vY7OzWjuUiaa"},"outputs":[],"source":["def test_sanity_check():\n","\n","    x = Value(-4.0)\n","    z = 2 * x + 2 + x\n","  \n","    q = z.relu() + z * x\n","    h = (z * z).relu()\n","    y = h + q + q * x\n","    y.backward()\n","    xmg, ymg = x, y\n","\n","    x = torch.Tensor([-4.0]).double()\n","    x.requires_grad = True\n","    z = 2 * x + 2 + x\n","    q = z.relu() + z * x\n","    h = (z * z).relu()\n","    y = h + q + q * x\n","    y.backward()\n","    xpt, ypt = x, y\n","\n","    \n","    # forward pass went well\n","    assert ymg.data == ypt.data.item()\n","    # backward pass went well\n","    print(xmg, xpt, xpt.grad)\n","    assert xmg.grad == xpt.grad.item()\n","\n","\n","def test_more_ops():\n","\n","    a = Value(-4.0)\n","    b = Value(2.0)\n","    c = a + b\n","    d = a * b + b**3\n","    c += c + 1\n","    c += 1 + c + (-a)\n","    d += d * 2 + (b + a).relu()\n","    d += 3 * d + (b - a).relu()\n","    e = c - d\n","    f = e**2\n","    g = f / 2.0\n","    g += 10.0 / f\n","    g.backward()\n","    amg, bmg, gmg = a, b, g\n","\n","    a = torch.Tensor([-4.0]).double()\n","    b = torch.Tensor([2.0]).double()\n","    a.requires_grad = True\n","    b.requires_grad = True\n","    c = a + b\n","    d = a * b + b**3\n","    c = c + c + 1\n","    c = c + 1 + c + (-a)\n","    d = d + d * 2 + (b + a).relu()\n","    d = d + 3 * d + (b - a).relu()\n","    e = c - d\n","    f = e**2\n","    g = f / 2.0\n","    g = g + 10.0 / f\n","    g.backward()\n","    apt, bpt, gpt = a, b, g\n","\n","    tol = 1e-6\n","    # forward pass went well\n","    assert abs(gmg.data - gpt.data.item()) < tol\n","    # backward pass went well\n","    assert abs(amg.grad - apt.grad.item()) < tol\n","    assert abs(bmg.grad - bpt.grad.item()) < tol"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":832,"status":"ok","timestamp":1670258029272,"user":{"displayName":"Ярослав Паламарчук","userId":"08021972334549004098"},"user_tz":-180},"id":"1LgTiYeZ-WGk"},"outputs":[{"name":"stdout","output_type":"stream","text":["Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"]}],"source":["a = Value(-4.0)\n","b = Value(2.0)\n","d = Value(3.0)\n","\n","c = a + b\n","e = c * d\n","e.backward()\n","\n","test_sanity_check()\n","test_more_ops()"]},{"cell_type":"markdown","metadata":{"id":"o-KbDOhMYHZ1"},"source":["# Обучение на основе собственной бибилотеки"]},{"cell_type":"markdown","metadata":{"id":"uVK1JLXom0Ze"},"source":["## Многослойный перцептрон на основе класса Value"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"rkl70dxhkcQN"},"outputs":[],"source":["import random\n","\n","#create fully connected perceptron based on Value class\n","\n","class Module(Value):\n","\n","    def zero_grad(self):\n","        for p in self.parameters():\n","            p.grad = 0\n","            \n","    def parameters(self):\n","        return []\n","\n","class Neuron(Module):\n","\n","    def __init__(self, nin, nonlin=True):\n","        self.w = np.random.randn(nin)\n","        self.b = np.random.randn(1)\n","        self.nonlin = nonlin\n","\n","    def __call__(self, x):\n","        act = np.dot(self.w, x) + self.b\n","        return act if not self.nonlin else max(0, act)\n","\n","    def parameters(self):\n","        return [self.w, self.b]\n","\n","    def __repr__(self):\n","        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n","\n","class Layer(Module):\n","\n","    def __init__(self, nin, nout, **kwargs):\n","        self.neurons = [Neuron(nin, **kwargs) for _ in range(nout)]\n","\n","    def __call__(self, x):\n","        out = [neuron(x) for neuron in self.neurons]\n","        return out[0] if len(out) == 1 else out\n","\n","    def parameters(self):\n","        return [p for neuron in self.neurons for p in neuron.parameters()]\n","\n","    def __repr__(self):\n","        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n","\n","class MLP(Module):\n","\n","    def __init__(self, nin, nouts):\n","        sz = [nin] + nouts\n","        self.layers = [Layer(sz[i], sz[i+1], nonlin=(i!=len(nouts)-1)) for i in range(len(nouts))]\n","        \n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def parameters(self):\n","        return [p for layer in self.layers for p in layer.parameters()]\n","\n","    def __repr__(self):\n","        repr = '\\n'.join(str(layer) for layer in self.layers)\n","        return f\"MLP of [{repr}]\""]},{"cell_type":"markdown","metadata":{"id":"YkkaE1V1m5i5"},"source":["## Обучение многослойного перцептрона"]},{"cell_type":"markdown","metadata":{"id":"WWy-H8eCn2zm"},"source":["Сам перцептрон"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"3La6nRi4m920"},"outputs":[{"name":"stdout","output_type":"stream","text":["MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)]\n","Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)]\n","Layer of [LinearNeuron(4)]]\n","number of parameters 18\n"]}],"source":["nn = MLP(3, [4, 4, 1])\n","print(nn)\n","print(\"number of parameters\", len(nn.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"OvkZVOLcnvqu"},"source":["Набор данных"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"aLJULsNanpVC"},"outputs":[],"source":["xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5],\n","  [0.5, 1.0, 1.0],\n","  [1.0, 1.0, -1.0],\n","]\n","ys = [1.0, -1.0, -1.0, 1.0] # desired targets"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"OuCTaTB8n5l0"},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'grad'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn [84], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (y_pred \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m (y \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39m# backward (zero_grad + backward)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m nn\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     13\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     14\u001b[0m \u001b[39m# update\u001b[39;00m\n","Cell \u001b[1;32mIn [81], line 9\u001b[0m, in \u001b[0;36mModule.zero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzero_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters():\n\u001b[1;32m----> 9\u001b[0m         p\u001b[39m.\u001b[39;49mgrad \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n","\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'grad'"]}],"source":["for k in range(20):\n","\n","    # forward\n","    total_loss = 0\n","    acc = 0\n","    for x, y in zip(xs, ys): # iterate over dataset\n","        y_pred = nn(x) # forward pass\n","        loss = (y_pred - y)**2 # calculate loss (mean square error)\n","        total_loss += loss\n","        acc += (y_pred > 0) == (y > 0)\n","    # backward (zero_grad + backward)\n","    nn.zero_grad()\n","    loss.backward()\n","    # update\n","    learning_rate = 0.1\n","    for p in nn.parameters():\n","        p.data -= learning_rate * p.grad\n","            \n","    if k % 1 == 0:\n","        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"]},{"cell_type":"markdown","metadata":{"id":"n4maaWL5yg-f"},"source":["# Домашнее задание"]},{"cell_type":"markdown","metadata":{"id":"2yyK39RYo084"},"source":["**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`"]},{"cell_type":"markdown","metadata":{"id":"FdzPyQ-hylKH"},"source":["**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n","[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGMpj9Pf61n2"},"outputs":[],"source":["# Ваш код"]},{"cell_type":"markdown","metadata":{"id":"3VPpRO6H6SHF"},"source":["**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YJfxtqSphFs"},"outputs":[],"source":["# Ваш код"]},{"cell_type":"markdown","metadata":{"id":"nRRgw0HNsr_a"},"source":["**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно."]},{"cell_type":"markdown","metadata":{"id":"W5AWW52REfn5"},"source":["https://docs.wandb.ai/guides/integrations/pytorch"]},{"cell_type":"markdown","metadata":{"id":"ekFfy3cWVOIW"},"source":["https://docs.wandb.ai/ref/python/watch  "]},{"cell_type":"markdown","metadata":{"id":"9G4SOp28ok0o"},"source":["https://docs.wandb.ai/guides/track/jupyter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lumiR8oykL04"},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw3c6P7BkP9b"},"outputs":[],"source":["!wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udPv0ufwkxOv"},"outputs":[],"source":["import wandb\n","run = wandb.init(project=\"polynom_learning_\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xtpc9MAUodNs"},"outputs":[],"source":["run.finish()"]}],"metadata":{"colab":{"collapsed_sections":["MRuSrP7JQ00i","1b95Z8u7Q3OL"],"provenance":[{"file_id":"1PkQAjVNo5ZLZcWqSvJ1cEiwCKGi1rPim","timestamp":1670254286341},{"file_id":"1EU3DbXL-rWn4_oN1Uo9uW4d1a-vATjkc","timestamp":1662646792259}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":0}
